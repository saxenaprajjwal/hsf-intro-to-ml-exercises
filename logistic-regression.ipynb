{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9287000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from utils import load_house_data, plot_housing_data_classified, \\\n",
    "    animate_logistic_regression, plot_fit_landscape_and_loss\n",
    "\n",
    "sizes, prices, labels = load_house_data('data/housing_prices.txt')\n",
    "\n",
    "plot_housing_data_classified(sizes, prices, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input features (as in the previous exercise)\n",
    "size_scaled = (sizes - np.mean(sizes)) / np.mean(sizes)\n",
    "price_scaled = (prices - np.mean(prices)) / np.mean(prices)\n",
    "\n",
    "# Create feature list: [size, price, size^2, price^2]\n",
    "# (use the scaled features!)\n",
    "####### YOUR CODE HERE #######\n",
    "features = [\n",
    "    size_scaled,           # Feature 0: size\n",
    "    price_scaled,          # Feature 1: price  \n",
    "    size_scaled**2,      # Feature 2: size^2\n",
    "    price_scaled**2      # Feature 3: price^2\n",
    "]\n",
    "####### END YOUR CODE ########\n",
    "\n",
    "# Convert to numpy array for easier computation\n",
    "# (We also need to transpose the array))\n",
    "feature_matrix = np.array(features).T\n",
    "\n",
    "feature_names = ['size', 'price', 'size²', 'price²']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    # To prevent overflow in the exponential function, we clip z\n",
    "    z = np.clip(z, -500, 500)\n",
    "    ####### YOUR CODE HERE #######\n",
    "    return ...\n",
    "    ####### END YOUR CODE ########\n",
    "\n",
    "\n",
    "def calculate_logistic_loss(weights, bias, feature_matrix, labels):\n",
    "    \"\"\"Calculate logistic loss for any number of features\"\"\"\n",
    "    # Linear combination: z = w1*x1 + w2*x2 + ... + wn*xn + b\n",
    "\n",
    "    # Calculate the linear combination\n",
    "    # Recall: the linear combination is z = w1*x1 + w2*x2 + ... + wn*xn + b\n",
    "    # where weights is a vector of shape (n_features,) and features is a matrix of shape (n_samples, n_features).\n",
    "    # The bias is a scalar.\n",
    "    # we can use np.dot to compute the dot product between features and weights, and then add the bias.\n",
    "    # this results in a vector z of shape (n_samples,).\n",
    "    z = np.dot(feature_matrix, weights) + bias\n",
    "\n",
    "    # Apply the sigmoid function to get predictions\n",
    "    ##### YOUR CODE HERE #######\n",
    "    y_pred = ...\n",
    "    ####### END YOUR CODE ########\n",
    "    \n",
    "    # clip to avoid log(0) issues\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Implement the binary cross-entropy loss\n",
    "    # Recall: L = -(1/N) * Σ [y * log(y_pred) + (1 - y) * log(1 - y_pred)]\n",
    "    ##### YOUR CODE HERE #######\n",
    "    loss = ...\n",
    "    ####### END YOUR CODE ########\n",
    "    return loss\n",
    "\n",
    "\n",
    "def gradient_descent_logistic(feature_matrix, labels, learning_rate=0.05, n_iterations=150):\n",
    "    \"\"\"Perform gradient descent for logistic regression with any number of features\"\"\"\n",
    "    n_features = feature_matrix.shape[1]\n",
    "    \n",
    "    # Initialize parameters\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0.0\n",
    "    \n",
    "    # Store training history\n",
    "    weights_history = [weights.copy()]\n",
    "    bias_history = [bias]\n",
    "    loss_history = [calculate_logistic_loss(weights, bias, feature_matrix, labels)]\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Forward pass\n",
    "        # Calculate the linear combination\n",
    "        z = np.dot(feature_matrix, weights) + bias\n",
    "\n",
    "        # Apply the sigmoid function to get predictions\n",
    "        ##### YOUR CODE HERE #######\n",
    "        y_pred = ...\n",
    "        ####### END YOUR CODE ########\n",
    "\n",
    "        # Calculate gradients\n",
    "        error = y_pred - labels\n",
    "        weight_gradients = np.dot(feature_matrix.T, error) / len(labels)\n",
    "        bias_gradient = np.mean(error)\n",
    "        \n",
    "        # Update parameters\n",
    "        ####### YOUR CODE HERE #######\n",
    "        weights -= ...\n",
    "        bias -= ...\n",
    "        ####### END YOUR CODE ########\n",
    "        \n",
    "        # Store history\n",
    "        weights_history.append(weights.copy())\n",
    "        bias_history.append(bias)\n",
    "        current_loss = calculate_logistic_loss(weights, bias, feature_matrix, labels)\n",
    "        loss_history.append(current_loss)\n",
    "    \n",
    "    return np.array(weights_history), np.array(bias_history), np.array(loss_history)\n",
    "\n",
    "\n",
    "weights_history, bias_history, loss_history = gradient_descent_logistic(\n",
    "    feature_matrix, labels, learning_rate=5.0, n_iterations=150\n",
    ")\n",
    "        \n",
    "# Create animation\n",
    "anim = animate_logistic_regression(\n",
    "    feature_matrix, labels, weights_history, bias_history, loss_history, feature_names,\n",
    "    # save_path=\"output/nonlinear_logistic_regression.mp4\"\n",
    ")\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(anim.to_jshtml())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
